# Project 2: Image Captioning

## Project Overview
In this project a neural network architecture was created to automatically generate captions from images.

Using the Microsoft Common Objects in COntext [(MS COCO) dataset](http://cocodataset.org/#home) to train the network, the network was tested on a novel set of images.  Network architecture included a CNN image encoder (Resnet Architecture and Training weights) and an RNN decoder (GRU) to generate image captions.  All networks were developed in PyTorch.
